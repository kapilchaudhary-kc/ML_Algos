# -*- coding: utf-8 -*-
"""perceptron.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DPu7jaaWrC2TgErFeukIzliApeh3Dq2i
"""

import numpy as np
import pandas as pd

class Perceptron():
  def __init__(self,epochs=1000,learning_rate=0.01):
    self.epochs=epochs
    self.learning_rate=learning_rate
    self.w=None

  @staticmethod
  def step(z):
    return 1 if z>0 else 0

  def fit(self,X,y):
    w=np.random.random(size=X.shape[1]+1)
    X=np.insert(X,0,1,axis=1)
    for i in range(self.epochs):
      j=np.random.randint(0,high=X.shape[0]) # Here I've selected samples randomly from training data.
      y_pred=self.step(np.dot(X[j],w))
      w=w+(self.learning_rate)*(y[j]-y_pred)*X[j]
      #print("epoch{}-----{},{}".format(i,w[0],w[1:]))
      self.w=w
    return w[0],w[1:]



  def predict(self,X_test):
    X_test=np.insert(X_test,0,1,axis=0)
    y=self.step(np.dot(X_test,(self.w)))
    return y

from sklearn.datasets import make_classification

X,y=make_classification(n_samples=1000,n_features=5,n_informative=2,random_state=23)

per=Perceptron()

per.fit(X,y)

per.predict(X[10])

class Perceptron():
  def __init__(self,epochs=1000,learning_rate=0.01):
    self.epochs=epochs #Epochs Initialization
    self.learning_rate=learning_rate #Learning Rate Initialization
    self.w=None # Weights initialization

  @staticmethod
  def step(z):
    return 1 if z>0 else 0

  def fit(self,X,y):
    w=np.random.random(size=X.shape[1]+1)
    X=np.insert(X,0,1,axis=1)
    for i in range(self.epochs):
      for j in range(X.shape[0]): #Here I've not selected the sample but taken complete feature sets values one by one
        y_pred=self.step(np.dot(X[j],w))
        w=w+(self.learning_rate)*(y[j]-y_pred)*X[j]

    self.w=w
    return w[0],w[1:]

  def predict(self,X_test):
    X_test=np.insert(X_test,0,1,axis=0)
    y=self.step(np.dot(X_test,(self.w)))
    return y

per1=Perceptron()

per1.fit(X,y)

per1.predict(X[10])

y[10]

